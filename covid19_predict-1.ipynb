{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "arabic-asthma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "minimal-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./time_series_covid19_confirmed_global.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "occasional-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Province/State', axis=1, inplace=True)\n",
    "data.drop('Lat', axis=1, inplace=True)\n",
    "data.drop('Long', axis=1, inplace=True)\n",
    "data.columns = np.concatenate((np.array(['Country/Region']),np.arange(len(data.columns[1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unexpected-captain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "      <th>611</th>\n",
       "      <th>612</th>\n",
       "      <th>613</th>\n",
       "      <th>614</th>\n",
       "      <th>615</th>\n",
       "      <th>616</th>\n",
       "      <th>617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154712</td>\n",
       "      <td>154757</td>\n",
       "      <td>154800</td>\n",
       "      <td>154960</td>\n",
       "      <td>154960</td>\n",
       "      <td>154960</td>\n",
       "      <td>155072</td>\n",
       "      <td>155093</td>\n",
       "      <td>155128</td>\n",
       "      <td>155174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>164276</td>\n",
       "      <td>165096</td>\n",
       "      <td>165864</td>\n",
       "      <td>166690</td>\n",
       "      <td>167354</td>\n",
       "      <td>167893</td>\n",
       "      <td>168188</td>\n",
       "      <td>168782</td>\n",
       "      <td>169462</td>\n",
       "      <td>170131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>201948</td>\n",
       "      <td>202122</td>\n",
       "      <td>202283</td>\n",
       "      <td>202449</td>\n",
       "      <td>202574</td>\n",
       "      <td>202722</td>\n",
       "      <td>202877</td>\n",
       "      <td>203045</td>\n",
       "      <td>203198</td>\n",
       "      <td>203359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15140</td>\n",
       "      <td>15153</td>\n",
       "      <td>15156</td>\n",
       "      <td>15167</td>\n",
       "      <td>15167</td>\n",
       "      <td>15167</td>\n",
       "      <td>15189</td>\n",
       "      <td>15192</td>\n",
       "      <td>15209</td>\n",
       "      <td>15222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52968</td>\n",
       "      <td>53387</td>\n",
       "      <td>53840</td>\n",
       "      <td>54280</td>\n",
       "      <td>54795</td>\n",
       "      <td>55121</td>\n",
       "      <td>55583</td>\n",
       "      <td>56040</td>\n",
       "      <td>56583</td>\n",
       "      <td>56583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>707436</td>\n",
       "      <td>718963</td>\n",
       "      <td>728435</td>\n",
       "      <td>736972</td>\n",
       "      <td>746678</td>\n",
       "      <td>756689</td>\n",
       "      <td>766051</td>\n",
       "      <td>770640</td>\n",
       "      <td>779398</td>\n",
       "      <td>790755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>388470</td>\n",
       "      <td>390369</td>\n",
       "      <td>392452</td>\n",
       "      <td>394683</td>\n",
       "      <td>395677</td>\n",
       "      <td>396746</td>\n",
       "      <td>398946</td>\n",
       "      <td>400649</td>\n",
       "      <td>402255</td>\n",
       "      <td>403716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8752</td>\n",
       "      <td>8789</td>\n",
       "      <td>8830</td>\n",
       "      <td>8861</td>\n",
       "      <td>8891</td>\n",
       "      <td>8934</td>\n",
       "      <td>8988</td>\n",
       "      <td>9016</td>\n",
       "      <td>9039</td>\n",
       "      <td>9067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>208599</td>\n",
       "      <td>208676</td>\n",
       "      <td>208715</td>\n",
       "      <td>208778</td>\n",
       "      <td>208829</td>\n",
       "      <td>208857</td>\n",
       "      <td>208867</td>\n",
       "      <td>208912</td>\n",
       "      <td>209002</td>\n",
       "      <td>209046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>128186</td>\n",
       "      <td>128804</td>\n",
       "      <td>129134</td>\n",
       "      <td>129134</td>\n",
       "      <td>129505</td>\n",
       "      <td>129625</td>\n",
       "      <td>129919</td>\n",
       "      <td>130272</td>\n",
       "      <td>130485</td>\n",
       "      <td>130820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows × 619 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country/Region  0  1  2  3  4  5  6  7  8  ...     608     609  \\\n",
       "0           Afghanistan  0  0  0  0  0  0  0  0  0  ...  154712  154757   \n",
       "1               Albania  0  0  0  0  0  0  0  0  0  ...  164276  165096   \n",
       "2               Algeria  0  0  0  0  0  0  0  0  0  ...  201948  202122   \n",
       "3               Andorra  0  0  0  0  0  0  0  0  0  ...   15140   15153   \n",
       "4                Angola  0  0  0  0  0  0  0  0  0  ...   52968   53387   \n",
       "..                  ... .. .. .. .. .. .. .. .. ..  ...     ...     ...   \n",
       "274             Vietnam  0  2  2  2  2  2  2  2  2  ...  707436  718963   \n",
       "275  West Bank and Gaza  0  0  0  0  0  0  0  0  0  ...  388470  390369   \n",
       "276               Yemen  0  0  0  0  0  0  0  0  0  ...    8752    8789   \n",
       "277              Zambia  0  0  0  0  0  0  0  0  0  ...  208599  208676   \n",
       "278            Zimbabwe  0  0  0  0  0  0  0  0  0  ...  128186  128804   \n",
       "\n",
       "        610     611     612     613     614     615     616     617  \n",
       "0    154800  154960  154960  154960  155072  155093  155128  155174  \n",
       "1    165864  166690  167354  167893  168188  168782  169462  170131  \n",
       "2    202283  202449  202574  202722  202877  203045  203198  203359  \n",
       "3     15156   15167   15167   15167   15189   15192   15209   15222  \n",
       "4     53840   54280   54795   55121   55583   56040   56583   56583  \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "274  728435  736972  746678  756689  766051  770640  779398  790755  \n",
       "275  392452  394683  395677  396746  398946  400649  402255  403716  \n",
       "276    8830    8861    8891    8934    8988    9016    9039    9067  \n",
       "277  208715  208778  208829  208857  208867  208912  209002  209046  \n",
       "278  129134  129134  129505  129625  129919  130272  130485  130820  \n",
       "\n",
       "[279 rows x 619 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "latest-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "Confirmed = {'Brazil':[],'India':[],'United Kingdom':[],'Russia':[],'US':[]}\n",
    "time_series = {'Brazil':[],'India':[],'United Kingdom':[],'Russia':[],'US':[]}\n",
    "for index,row in data.iterrows():\n",
    "    for key in Confirmed:\n",
    "        if row['Country/Region'] == key:\n",
    "            d = data.iloc[index][1:].astype(np.float32).values\n",
    "            time_series[key].append(d)\n",
    "            m = np.zeros_like(d)\n",
    "            for j in range(1,len(d)):\n",
    "                m[j] = d[j] - d[j-1]\n",
    "            Confirmed[key].append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0332b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series['United Kingdom'] = [np.sum(np.array(time_series['United Kingdom']),axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "toxic-optics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 618)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(time_series['United Kingdom']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2754001",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.array(time_series['Brazil']).squeeze())\n",
    "plt.plot(np.array(time_series['India']).squeeze())\n",
    "plt.plot(np.array(time_series['United Kingdom']).squeeze())\n",
    "plt.plot(np.array(time_series['Russia']).squeeze())\n",
    "plt.plot(np.array(time_series['US']).squeeze())\n",
    "plt.legend(['Brazil','India','UK','Russia','US'])\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('Number of confirmed people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pleased-reputation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "12\n",
      "1\n",
      "1\n",
      "618\n"
     ]
    }
   ],
   "source": [
    "print(len(Confirmed['Brazil']))\n",
    "print(len(Confirmed['India']))\n",
    "print(len(Confirmed['United Kingdom']))\n",
    "print(len(Confirmed['US']))\n",
    "print(len(Confirmed['Russia']))\n",
    "timeLength = len(Confirmed['Brazil'][0])\n",
    "print(timeLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moved-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "Confirmed['United Kingdom'] = [np.sum(np.array(Confirmed['United Kingdom']),axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aging-working",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'day')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(Confirmed['Russia'][0])\n",
    "plt.title('Number of confirmed cases in a single day in Russia')\n",
    "plt.xlabel('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "received-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length= 10\n",
    "delay = 1\n",
    "def func(country):\n",
    "    dataCountry = []\n",
    "    for i in range(timeLength - sequence_length -delay + 1):\n",
    "        dataCountry.append(Confirmed[country][0][i:i+sequence_length+delay])\n",
    "    dataCountry = np.array(dataCountry)\n",
    "    x_train = dataCountry[:,:sequence_length]\n",
    "    y_train = dataCountry[:,-1]\n",
    "    return np.expand_dims(x_train,2),y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legislative-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Brazil,y_Brazil = func('Brazil')\n",
    "x_India,y_India = func('India')\n",
    "x_Russia,y_Russia = func('Russia')\n",
    "x_UK,y_UK = func('United Kingdom')\n",
    "x_US,y_US = func('US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "empirical-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(country,x,y):\n",
    "    x = x / np.max(Confirmed[country][0])\n",
    "    y = y / np.max(Confirmed[country][0])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "formal-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Brazil, y_Brazil = norm('Brazil',x_Brazil, y_Brazil)\n",
    "x_India, y_India = norm('India',x_India, y_India)\n",
    "x_Russia, y_Russia = norm('Russia',x_Russia, y_Russia)\n",
    "x_UK, y_UK = norm('United Kingdom',x_UK, y_UK)\n",
    "x_US, y_US = norm('US',x_US,y_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "broke-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x_Brazil,test_x_Brazil,train_y_Brazil,test_y_Brazil = train_test_split(x_Brazil,y_Brazil)\n",
    "train_x_India,test_x_India,train_y_India,test_y_India = train_test_split(x_India,y_India)\n",
    "train_x_Russia,test_x_Russia,train_y_Russia,test_y_Russia = train_test_split(x_Russia,y_Russia)\n",
    "train_x_UK,test_x_UK,train_y_UK,test_y_UK = train_test_split(x_UK,y_UK)\n",
    "train_x_US,test_x_US,train_y_US,test_y_US = train_test_split(x_US,y_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "molecular-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "happy-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Brazil_dataset = Mydataset(train_x_Brazil,train_y_Brazil)\n",
    "test_Brazil_dataset = Mydataset(test_x_Brazil,test_y_Brazil)\n",
    "train_India_dataset = Mydataset(train_x_India,train_y_India)\n",
    "test_India_dataset = Mydataset(test_x_India,test_y_India)\n",
    "train_Russia_dataset = Mydataset(train_x_Russia,train_y_Russia)\n",
    "test_Russia_dataset = Mydataset(test_x_Russia,test_y_Russia)\n",
    "train_UK_dataset = Mydataset(train_x_UK,train_y_UK)\n",
    "test_UK_dataset = Mydataset(test_x_UK,test_y_UK)\n",
    "train_US_dataset = Mydataset(train_x_US,train_y_US)\n",
    "test_US_dataset = Mydataset(test_x_US,test_y_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "involved-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTACH_SIZE = 64\n",
    "train_Brazil_dl = torch.utils.data.DataLoader(train_Brazil_dataset,batch_size=BTACH_SIZE,shuffle=True)\n",
    "test_Brazil_dl = torch.utils.data.DataLoader(test_Brazil_dataset,batch_size=BTACH_SIZE)\n",
    "train_India_dl = torch.utils.data.DataLoader(train_India_dataset,batch_size=BTACH_SIZE,shuffle=True)\n",
    "test_India_dl = torch.utils.data.DataLoader(test_India_dataset,batch_size=BTACH_SIZE)\n",
    "train_Russia_dl = torch.utils.data.DataLoader(train_Russia_dataset,batch_size=BTACH_SIZE,shuffle=True)\n",
    "test_Russia_dl = torch.utils.data.DataLoader(test_Russia_dataset,batch_size=BTACH_SIZE)\n",
    "train_UK_dl = torch.utils.data.DataLoader(train_UK_dataset,batch_size=BTACH_SIZE,shuffle=True)\n",
    "test_UK_dl = torch.utils.data.DataLoader(test_UK_dataset,batch_size=BTACH_SIZE)\n",
    "train_US_dl = torch.utils.data.DataLoader(train_US_dataset,batch_size=BTACH_SIZE,shuffle=True)\n",
    "test_US_dl = torch.utils.data.DataLoader(test_US_dataset,batch_size=BTACH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fitted-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "class Net(nn.Module):\n",
    "    # GRU实现 \n",
    "    def __init__(self,hidden_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = 3\n",
    "        self.rnn = nn.GRU(1,hidden_size,num_layers=self.num_layers,batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.coff = nn.Parameter(torch.ones(1).squeeze()/2,requires_grad=True)\n",
    "    def forward(self,inputs):\n",
    "        _,hn = self.rnn(inputs)\n",
    "        x = F.dropout(F.relu(self.fc1(hn)))\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sum(x,axis=0)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            m = list() \n",
    "            for ele in inputs:\n",
    "                device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "                if device == 'cuda':\n",
    "                    ele = ele.squeeze().cpu().detach().numpy()\n",
    "                else:\n",
    "                    ele = ele.squeeze().detach().numpy()\n",
    "                res = self.ES_Forecast(ele,1)\n",
    "                m.append([res])\n",
    "            m = torch.as_tensor(m,dtype=torch.float32).to(device)\n",
    "        x = torch.cat((x,m),dim=1)\n",
    "        x = self.coff*x[:,0]+(1 - self.coff)*x[:,1]\n",
    "#         x = torch.mean(x,dim=1)\n",
    "#         x = self.mix1(x)\n",
    "#         x = self.mix2(x)\n",
    "        x = F.relu(x)\n",
    "        return x.squeeze()\n",
    "    def ES_Forecast(self,A,T):\n",
    "        yt,n = A,len(A)\n",
    "        alpha, st1_0 = 0.3,np.mean(yt[0:3])\n",
    "        st2_0, st3_0 = st1_0, st1_0\n",
    "        st1,st2,st3 = list(),list(),list()\n",
    "        st1.append(alpha*yt[0]+(1-alpha)*st1_0)\n",
    "        st2.append(alpha*st1[0]+(1-alpha)*st2_0)\n",
    "        st3.append(alpha*st2[0]+(1-alpha)*st3_0)\n",
    "        for i in range(1,n):\n",
    "            st1.append(alpha*yt[i]+(1-alpha)*st1[i-1])\n",
    "            st2.append(alpha*st1[i]+(1-alpha)*st2[i-1])\n",
    "            st3.append(alpha*st2[i]+(1-alpha)*st3[i-1])\n",
    "        a = 3*st1[-1] - 3*st2[-1]+st3[-1]\n",
    "        b = 0.5*alpha/((1-alpha)**2)*((6-5*alpha)*st1[-1]-2*(5-4*alpha)*st2[-1]+(4-3*alpha)*st3[-1])\n",
    "        c = 0.5*alpha**2/(1-alpha)**2*(st1[-1]-2*st2[-1]+st3[-1])\n",
    "        coff = [c,b,a]\n",
    "        res = c*T**2+b*T+a\n",
    "        return res\n",
    "        \n",
    "# class Net(nn.Module):\n",
    "#     # LSTM实现 \n",
    "#     def __init__(self, hidden_size):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.rnn = nn.LSTM(1, hidden_size,num_layers=4,batch_first=True)\n",
    "#         self.fc1 = nn.Linear(hidden_size, 256)\n",
    "#         self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         _, s_o = self.rnn(inputs)\n",
    "#         s_o = s_o[-1]\n",
    "#         x = F.dropout(F.relu(self.fc1(s_o)))\n",
    "#         x = self.fc2(x)\n",
    "#         x = torch.sum(x,axis=0)\n",
    "#         return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "smoking-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Brazil = Net(hidden_size)\n",
    "model_India = Net(hidden_size)\n",
    "model_Russia = Net(hidden_size)\n",
    "model_UK = Net(hidden_size)\n",
    "model_US = Net(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "equal-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_India.to('cuda')\n",
    "    model_Brazil.to('cuda')\n",
    "    model_Russia.to('cuda')\n",
    "    model_UK.to('cuda')\n",
    "    model_US.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "juvenile-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer_Brazil = torch.optim.Adam(model_Brazil.parameters(), lr=5e-4)\n",
    "optimizer_India = torch.optim.Adam(model_India.parameters(), lr=5e-4)\n",
    "optimizer_Russia = torch.optim.Adam(model_Russia.parameters(), lr=5e-4)\n",
    "optimizer_UK = torch.optim.Adam(model_UK.parameters(), lr=5e-4)\n",
    "optimizer_US = torch.optim.Adam(model_US.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "proper-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, trainloader, testloader,optimizer):\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in trainloader:\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            total += y.size(0)\n",
    "            running_loss += loss.item()\n",
    "#    exp_lr_scheduler.step()\n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "        \n",
    "        \n",
    "    test_total = 0\n",
    "    test_running_loss = 0 \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            if torch.cuda.is_available():\n",
    "                x, y = x.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_total += y.size(0)\n",
    "            test_running_loss += loss.item()\n",
    "    \n",
    "    epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
    "        \n",
    "#     print('epoch: ', epoch, \n",
    "#           'loss： ', round(epoch_loss, 6),\n",
    "#           'test_loss： ', round(epoch_test_loss, 6),\n",
    "#              )\n",
    "        \n",
    "    return epoch_loss, epoch_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "confidential-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltLoss(train_loss,test_loss,name):\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(test_loss)\n",
    "    plt.legend(['train_loss','test_loss'])\n",
    "    plt.xlabel('epochs')\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "approved-failing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:51<00:00,  3.91it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "bestModel_Brazil = None\n",
    "bestLoss = np.inf\n",
    "for epoch in tqdm(range(epochs),total=epochs,smoothing=0.9):\n",
    "    epoch_loss, epoch_test_loss = fit(epoch,model_Brazil,train_Brazil_dl,test_Brazil_dl,optimizer_Brazil)\n",
    "    train_loss.append(epoch_loss)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    if epoch_test_loss<bestLoss:\n",
    "        bestLoss = epoch_test_loss\n",
    "        bestModel_Brazil = model_Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "automotive-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "pltLoss(train_loss,test_loss,'Brazil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "reliable-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:50<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "bestModel_India = None\n",
    "bestLoss = np.inf\n",
    "for epoch in tqdm(range(epochs),total=epochs,smoothing=0.9):\n",
    "    epoch_loss, epoch_test_loss = fit(epoch,model_India,train_India_dl,test_India_dl,optimizer_India)\n",
    "    train_loss.append(epoch_loss)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    if epoch_test_loss < bestLoss:\n",
    "        bestLoss = epoch_test_loss\n",
    "        bestModel_India = model_India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "advance-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "pltLoss(train_loss,test_loss,'India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caring-charm",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:50<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "bestModel_Russia = None\n",
    "bestLoss = np.inf\n",
    "for epoch in tqdm(range(epochs),total=epochs,smoothing=0.9):\n",
    "    epoch_loss, epoch_test_loss = fit(epoch,model_Russia,train_Russia_dl,test_Russia_dl,optimizer_Russia)\n",
    "    train_loss.append(epoch_loss)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    if epoch_test_loss<bestLoss:\n",
    "        bestLoss = epoch_test_loss\n",
    "        bestModel_Russia = model_Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "pltLoss(train_loss,test_loss,'Russia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "italian-sense",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:50<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "bestModel_UK = None\n",
    "bestLoss = np.inf\n",
    "for epoch in tqdm(range(epochs),total=epochs,smoothing=0.9):\n",
    "    epoch_loss, epoch_test_loss = fit(epoch,model_UK,train_UK_dl,test_UK_dl,optimizer_UK)\n",
    "    train_loss.append(epoch_loss)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    if epoch_test_loss<bestLoss:\n",
    "        bestLoss = epoch_test_loss\n",
    "        bestModel_UK = model_UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "pltLoss(train_loss,test_loss,'UK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sublime-manor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:50<00:00,  3.94it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 200\n",
    "bestModel_US = None\n",
    "bestLoss = np.inf\n",
    "for epoch in tqdm(range(epochs),total=epochs,smoothing=0.9):\n",
    "    epoch_loss, epoch_test_loss = fit(epoch,model_US,train_US_dl,test_US_dl,optimizer_US)\n",
    "    train_loss.append(epoch_loss)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    if epoch_test_loss<bestLoss:\n",
    "        bestLoss = epoch_test_loss\n",
    "        bestModel_US = model_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "pltLoss(train_loss,test_loss,'US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2db6b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = train_x_Brazil.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08717a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'day')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(range(1,n+1),bestModel_US(torch.from_numpy(train_x_US).to('cuda')).detach().cpu().numpy())\n",
    "plt.scatter(range(1,n+1),train_y_US)\n",
    "plt.legend(['Predicted','Ground truth'])\n",
    "plt.title('US')\n",
    "plt.xlabel('day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-painting",
   "metadata": {},
   "source": [
    "# India Brazil Russia UK US未来预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "western-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "x4pred_bra = Confirmed['Brazil'][0][-sequence_length:]/np.max(Confirmed['Brazil'][0])\n",
    "x4pred_ind = Confirmed['India'][0][-sequence_length:]/np.max(Confirmed['India'][0])\n",
    "x4pred_rus = Confirmed['Russia'][0][-sequence_length:]/np.max(Confirmed['Russia'][0])\n",
    "x4pred_UK = Confirmed['United Kingdom'][0][-sequence_length:]/np.max(Confirmed['United Kingdom'][0])\n",
    "x4pred_US = Confirmed['US'][0][-sequence_length:]/np.max(Confirmed['US'][0])\n",
    "ptr = 0\n",
    "POINT_NUM = 61\n",
    "while ptr<POINT_NUM:\n",
    "    x_input = np.expand_dims(x4pred_bra[ptr:ptr+sequence_length],(0,2))\n",
    "    out = bestModel_Brazil(torch.as_tensor(x_input,dtype=torch.float).cuda())\n",
    "    out = out.cpu().detach().numpy().reshape(1,)\n",
    "    x4pred_bra = np.concatenate((x4pred_bra,out))\n",
    "    \n",
    "    x_input = np.expand_dims(x4pred_ind[ptr:ptr+sequence_length],(0,2))\n",
    "    out = bestModel_India(torch.as_tensor(x_input,dtype=torch.float).cuda())\n",
    "    out = out.cpu().detach().numpy().reshape(1,)\n",
    "    x4pred_ind = np.concatenate((x4pred_ind,out))\n",
    "    \n",
    "    x_input = np.expand_dims(x4pred_rus[ptr:ptr+sequence_length],(0,2))\n",
    "    out = bestModel_Russia(torch.as_tensor(x_input,dtype=torch.float).cuda())\n",
    "    out = out.cpu().detach().numpy().reshape(1,)\n",
    "    x4pred_rus = np.concatenate((x4pred_rus,out))\n",
    "    \n",
    "    x_input = np.expand_dims(x4pred_US[ptr:ptr+sequence_length],(0,2))\n",
    "    out = bestModel_US(torch.as_tensor(x_input,dtype=torch.float).cuda())\n",
    "    out = out.cpu().detach().numpy().reshape(1,)\n",
    "    x4pred_US = np.concatenate((x4pred_US,out))\n",
    "    \n",
    "    x_input = np.expand_dims(x4pred_UK[ptr:ptr+sequence_length],(0,2))\n",
    "    out = bestModel_UK(torch.as_tensor(x_input,dtype=torch.float).cuda())\n",
    "    out = out.cpu().detach().numpy().reshape(1,)\n",
    "    x4pred_UK = np.concatenate((x4pred_UK,out))\n",
    "    \n",
    "    ptr += 1\n",
    "x4pred_bra = x4pred_bra[-POINT_NUM:]*np.max(Confirmed['Brazil'][0])\n",
    "x4pred_ind = x4pred_ind[-POINT_NUM:]*np.max(Confirmed['India'][0])\n",
    "x4pred_rus = x4pred_rus[-POINT_NUM:]*np.max(Confirmed['Russia'][0])\n",
    "x4pred_US = x4pred_US[-POINT_NUM:]*np.max(Confirmed['US'][0])\n",
    "x4pred_UK = x4pred_UK[-POINT_NUM:]*np.max(Confirmed['United Kingdom'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "exclusive-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mPlot(string,d):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(timeLength),Confirmed[string][0])\n",
    "    plt.plot(np.arange(timeLength,timeLength+POINT_NUM),d)\n",
    "    plt.legend(['Known','Predicted'])\n",
    "    plt.xlabel('day')\n",
    "    plt.title(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fabulous-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "mPlot('Brazil',x4pred_bra)\n",
    "mPlot('India',x4pred_ind)\n",
    "mPlot('Russia',x4pred_rus)\n",
    "mPlot('United Kingdom',x4pred_UK)\n",
    "mPlot('US',x4pred_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "boxed-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calRes(x1,x2):\n",
    "    temp = np.concatenate((x1,x2))\n",
    "    return np.cumsum(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "federal-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "bra = calRes(Confirmed['Brazil'][0],x4pred_bra)\n",
    "ind = calRes(Confirmed['India'][0],x4pred_ind)\n",
    "rus = calRes(Confirmed['Russia'][0],x4pred_rus)\n",
    "UK = calRes(Confirmed['United Kingdom'][0],x4pred_UK)\n",
    "US = calRes(Confirmed['US'][0],x4pred_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "contemporary-professional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total confirmed')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(bra)\n",
    "plt.plot(ind)\n",
    "plt.plot(rus)\n",
    "plt.plot(UK)\n",
    "plt.plot(US)\n",
    "plt.scatter([timeLength for _ in range(50)],np.linspace(0,np.max(US)),s=1)\n",
    "plt.legend(['Brazil','India','Russia','UK','US'])\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('Total confirmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6cdf1a",
   "metadata": {},
   "source": [
    "# 生成结果csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "found-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "x4pred_bra = bra[-31:]\n",
    "x4pred_ind = ind[-31:]\n",
    "x4pred_rus = rus[-31:]\n",
    "x4pred_UK = UK[-31:]\n",
    "x4pred_US = US[-31:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a73ea146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=[\"Brazil\",\"India\",\"Russia\",\"United Kindom\",\"United States\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1b2bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Brazil\"] = x4pred_bra\n",
    "df[\"India\"] = x4pred_ind\n",
    "df[\"Russia\"] = x4pred_rus\n",
    "df[\"United Kindom\"] = x4pred_UK\n",
    "df[\"United States\"] = x4pred_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51e4bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
